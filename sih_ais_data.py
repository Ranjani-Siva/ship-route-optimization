# -*- coding: utf-8 -*-
"""sih ais data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16sxQvGoYLpPsBdd07Am-mu2tOBEdOMtK
"""

import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import skew, kurtosis

# Download the zip file
!wget -O AIS_data.zip https://coast.noaa.gov/htdata/CMSP/AISDataHandler/2024/AIS_2024_01_01.zip

# Unzip the file
import zipfile
import os

with zipfile.ZipFile('AIS_data.zip', 'r') as zip_ref:
    zip_ref.extractall('AIS_data')

import pandas as pd

# Assuming the extracted folder contains CSV files, list the directory
extracted_files = os.listdir('AIS_data')

csv_file_path = os.path.join('AIS_data', extracted_files[0])  # Modify if you know the exact file

# Load the CSV into a pandas DataFrame
df = pd.read_csv(csv_file_path)

df.head()

df.info

df.shape

df.isnull().sum()

df = df.dropna()

# Step 5: Check the cleaned data
df.head()

df.isnull().sum()

df.shape

print(df.columns)

df.dtypes

df['BaseDateTime'] = pd.to_datetime(df['BaseDateTime'])
df.head()

df.describe()

import numpy as np

numerical_df = df.select_dtypes(include=['number'])
lower_percentile = np.percentile(numerical_df, 1)
upper_percentile = np.percentile(numerical_df, 99)

# Filter data
filtered_data = numerical_df[(numerical_df >= lower_percentile) & (numerical_df <= upper_percentile)]

filtered_data.head(5)

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
data_normalized = scaler.fit_transform(filtered_data)
datas=pd.DataFrame(data_normalized)
datas.columns=filtered_data.columns
datas.head(5)

datas.shape

# Function to determine the distribution type based on skewness and kurtosis
def determine_distribution(data):
    skewness = skew(data)
    kurt = kurtosis(data)

    if skewness > 0.5:
        return "Right-Skewed"
    elif skewness < -0.5:
        return "Left-Skewed"
    elif abs(skewness) < 0.5:
        if kurt < 0.5:
            return "Uniform Distribution"
        else:
            return "Normal Distribution"
    else:
        return "Unknown"

# Function to plot histograms and print distribution type
def plot_histogram_and_distribution(dataframe, feature_name):
    data = dataframe[feature_name].dropna()  # Drop NaN values if any

    # Check if the data type is numeric
    if pd.api.types.is_numeric_dtype(data):

        # Plot histogram
        plt.figure(figsize=(6, 4))
        sns.histplot(data, bins=30, kde=True, edgecolor='black')
        # Add labels and title
        plt.xlabel(feature_name)
        plt.ylabel('Frequency')
        plt.title(f'Histogram of {feature_name}')

        # Show plot
        plt.show()

        # Determine and print distribution type
        dist_type = determine_distribution(data)
        print(f"'{feature_name}' feature: {dist_type}")
    else:
        print(f"Skipping '{feature_name}' - Not a numeric data type")

# Plot histograms and print distribution type for each feature in the dataset
for feature in datas.columns:
    plot_histogram_and_distribution(datas, feature)

correlation_matrix = datas.corr()

# Plotting the correlation matrix using a heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix of Numerical Features')
plt.show()


# Create a scatter plot matrix to visualize relationships between multiple variables
sns.pairplot(datas)
plt.show()

# Scatter plot for variables
plt.figure(figsize=(8, 6))
plt.scatter(datas['Draft'], datas['Width'])
plt.xlabel('Draft')
plt.ylabel('Width')
plt.title('Check the relationship between Draft and Width')
plt.show()

# Scatter plot for variables
plt.figure(figsize=(8, 6))
plt.scatter(datas['Draft'], datas['Length'])
plt.xlabel('Draft')
plt.ylabel('Length')
plt.title('Check the relationship between Draft and Length')
plt.show()

# Scatter plot for variables
plt.figure(figsize=(8, 6))
plt.scatter(datas['Width'], datas['VesselType'])
plt.xlabel('Draft')
plt.ylabel('VesselType')
plt.title('Check the relationship between Draft and Vesseltype')
plt.show()

# prompt: with length, width as x and draft as y plot linear regression with acquracy

import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Select features (Length and Width) and target variable (Draft)
X = datas[['Length', 'Width']]
y = datas['Draft']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a linear regression model
model = LinearRegression()

# Train the model on the training data
model.fit(X_train, y_train)

# Make predictions on the test data
y_pred = model.predict(X_test)

# Evaluate the model's performance
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error (MSE): {mse}")
print(f"R-squared (R2): {r2}")


# Plot the linear regression line
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred)  # Actual vs. Predicted values
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)
plt.xlabel('Independent variables')
plt.ylabel('Dependent variable')
plt.title('Linear Regression: Draft Prediction')
plt.show()

from google.colab import drive
drive.mount('/content/drive')

df.to_csv('/content/drive/MyDrive/sih2024/2024_AIS.csv', index=False)